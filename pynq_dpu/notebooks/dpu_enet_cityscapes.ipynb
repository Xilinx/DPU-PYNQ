{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPU example: ENet\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim/s\n",
    "* This notebooks shows an example of DPU applications. The application,as well as the DPU IP, is pulled from the official \n",
    "[Vitis AI Github Repository](https://github.com/Xilinx/Vitis-AI).\n",
    "* Description: ENet for segmentation on Cityscapes.\n",
    "* Input size: 512*1024\n",
    "* Task: Segmentation\n",
    "\n",
    "## References\n",
    "* [Vitis AI Github Repository](https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html).\n",
    "\n",
    "## Last revised\n",
    "* Apr 20, 2023\n",
    "    * Initial revision\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the overlay\n",
    "We will download the overlay onto the board. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility functions\n",
    "\n",
    "In this section, we will prepare a few functions for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_model()` method will automatically prepare the `graph`\n",
    "which is used by VART.\n",
    "\n",
    "**Note** For the KV260 board you may see TLS memory allocation errors if cv2 gets loaded before loading the vitis libraries in the Jupyter Lab environment. Make sure to load cv2 first in these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"dpu_enet_cityscapes.xmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define a few useful preprocessing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pallete = [128, 64, 128, 244, 35, 232, 70, 70, 70, 102, 102, 156, 190, 153, 153, 153, 153, 153, 250, 170, 30,\n",
    "           220, 220, 0, 107, 142, 35, 152, 251, 152, 70, 130, 180, 220, 20, 60, 255, 0, 0, 0, 0, 142, 0, 0, 70,\n",
    "           0, 60, 100, 0, 80, 100, 0, 0, 230, 119, 11, 32 ]\n",
    "\n",
    "MEANS = [.485, .456, .406]\n",
    "STDS = [.229, .224, .225]\n",
    "\n",
    "def preprocess_fn(image):\n",
    "    image = image.astype(np.float32)\n",
    "    image =  image / 255.0\n",
    "    for j in range(3):\n",
    "        image[:, :, j] -= MEANS[j]\n",
    "    for j in range(3):\n",
    "        image[:, :, j] /= STDS[j]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that our original images are 2048x1024 so we need to preprocess them\n",
    "later to make sure it fits our model, which takes 1024x512 input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'img/segm'\n",
    "original_images = [i for i in os.listdir(image_folder) if i.endswith('png')]\n",
    "total_images = len(original_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use VART\n",
    "Now we should be able to use VART to do image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpu = overlay.runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)   # (1, 512, 1024, 3)\n",
    "shapeOut = tuple(outputTensors[0].dims) # (1, 512, 1024, 19)\n",
    "outputSize = int(outputTensors[0].get_data_size() / shapeIn[0]) # 9961472 = 512x1024x19 / 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a few buffers to store input and output data. They will be reused\n",
    "during multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we have a list of `original_images`. \n",
    "We can now define a new function `run()` which takes the image index as \n",
    "the input, then decode and post-process the output as the detection result.\n",
    "With the argument `display` set to `True`, the original image as well as the\n",
    "detected objects and their labels can be rendered.\n",
    "\n",
    "It is obvious that the range of `image_index` should be [0, `total_images`-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run(image_index, display=False):\n",
    "    # Read input image\n",
    "    input_image = cv2.imread(os.path.join(image_folder, original_images[image_index]))\n",
    "    \n",
    "    # Pre-processing\n",
    "    resized = cv2.resize(input_image,(1024,512))\n",
    "    preprocessed = preprocess_fn(resized)\n",
    "    \n",
    "    # Fetch data to DPU and trigger it\n",
    "    image[0,...] = preprocessed.reshape(shapeIn[1:])\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    \n",
    "    # Retrieve output data\n",
    "    classMap_numpy = np.argmax(output_data[0][0], axis=-1).astype(np.uint8)\n",
    "    classMap_numpy = Image.fromarray(classMap_numpy)\n",
    "    classMap_numpy_color = classMap_numpy.copy()\n",
    "    classMap_numpy_color.putpalette(pallete)\n",
    "    if display:\n",
    "        _, ax = plt.subplots(1)\n",
    "        _ = ax.imshow(classMap_numpy_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run(0, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run it for multiple images as shown below. In this example\n",
    "we have only used 1 thread; in principle, users should be able to boost\n",
    "the performance by employing more threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "[run(i) for i in range(total_images)]\n",
    "time2 = time.time()\n",
    "fps = total_images/(time2-time1)\n",
    "print(\"Performance: {} FPS\".format(fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to remove references to `vart.Runner` and let Python garbage-collect\n",
    "the unused graph objects. This will make sure we can run other notebooks without\n",
    "any issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del overlay\n",
    "del dpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Copyright (C) 2021 Xilinx, Inc\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0 License\n",
    "\n",
    "----\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
