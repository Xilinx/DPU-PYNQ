{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPU example: YOLOv3\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim/s\n",
    "* This notebooks shows an example of DPU applications. The application,as well as the DPU IP, is pulled from the official \n",
    "[Vitis AI Github Repository](https://github.com/Xilinx/Vitis-AI).\n",
    "\n",
    "## References\n",
    "* [Vitis AI Github Repository](https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html).\n",
    "\n",
    "## Last revised\n",
    "* Jun 27, 2022\n",
    "    * Initial revision\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the overlay\n",
    "We will download the overlay onto the board. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility functions\n",
    "\n",
    "In this section, we will prepare a few functions for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import colorsys\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_model()` method will automatically prepare the `graph`\n",
    "which is used by VART.\n",
    "\n",
    "**Note** For the KV260 board you may see TLS memory allocation errors if cv2 gets loaded before loading the vitis libraries in the Jupyter Lab environment. Make sure to load cv2 first in these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"yolov3_voc_tf.xmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define a few useful preprocessing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_list = [10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326]\n",
    "anchor_float = [float(x) for x in anchor_list]\n",
    "anchors = np.array(anchor_float).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get model classification information'''\t\n",
    "def get_class(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "    \n",
    "classes_path = \"img/voc_classes.txt\"\n",
    "class_names = get_class(classes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "colors = list(map(lambda x: \n",
    "                  (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), \n",
    "                  colors))\n",
    "random.seed(0)\n",
    "random.shuffle(colors)\n",
    "random.seed(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''resize image with unchanged aspect ratio using padding'''\n",
    "def letterbox_image(image, size):\n",
    "    ih, iw, _ = image.shape\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    #print(scale)\n",
    "    \n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "    #print(nw)\n",
    "    #print(nh)\n",
    "\n",
    "    image = cv2.resize(image, (nw,nh), interpolation=cv2.INTER_LINEAR)\n",
    "    new_image = np.ones((h,w,3), np.uint8) * 128\n",
    "    h_start = (h-nh)//2\n",
    "    w_start = (w-nw)//2\n",
    "    new_image[h_start:h_start+nh, w_start:w_start+nw, :] = image\n",
    "    return new_image\n",
    "\n",
    "\n",
    "'''image preprocessing'''\n",
    "def pre_process(image, model_image_size):\n",
    "    image = image[...,::-1]\n",
    "    image_h, image_w, _ = image.shape\n",
    " \n",
    "    if model_image_size != (None, None):\n",
    "        assert model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "        assert model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "        boxed_image = letterbox_image(image, tuple(reversed(model_image_size)))\n",
    "    else:\n",
    "        new_image_size = (image_w - (image_w % 32), image_h - (image_h % 32))\n",
    "        boxed_image = letterbox_image(image, new_image_size)\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0) \t\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also define a few functions to post-process the output after running a DPU task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_feats(feats, anchors, num_classes, input_shape):\n",
    "    num_anchors = len(anchors)\n",
    "    anchors_tensor = np.reshape(np.array(anchors, dtype=np.float32), [1, 1, 1, num_anchors, 2])\n",
    "    grid_size = np.shape(feats)[1:3]\n",
    "    nu = num_classes + 5\n",
    "    predictions = np.reshape(feats, [-1, grid_size[0], grid_size[1], num_anchors, nu])\n",
    "    grid_y = np.tile(np.reshape(np.arange(grid_size[0]), [-1, 1, 1, 1]), [1, grid_size[1], 1, 1])\n",
    "    grid_x = np.tile(np.reshape(np.arange(grid_size[1]), [1, -1, 1, 1]), [grid_size[0], 1, 1, 1])\n",
    "    grid = np.concatenate([grid_x, grid_y], axis = -1)\n",
    "    grid = np.array(grid, dtype=np.float32)\n",
    "\n",
    "    box_xy = (1/(1+np.exp(-predictions[..., :2])) + grid) / np.array(grid_size[::-1], dtype=np.float32)\n",
    "    box_wh = np.exp(predictions[..., 2:4]) * anchors_tensor / np.array(input_shape[::-1], dtype=np.float32)\n",
    "    box_confidence = 1/(1+np.exp(-predictions[..., 4:5]))\n",
    "    box_class_probs = 1/(1+np.exp(-predictions[..., 5:]))\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "\n",
    "def correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "    input_shape = np.array(input_shape, dtype = np.float32)\n",
    "    image_shape = np.array(image_shape, dtype = np.float32)\n",
    "    new_shape = np.around(image_shape * np.min(input_shape / image_shape))\n",
    "    offset = (input_shape - new_shape) / 2. / input_shape\n",
    "    scale = input_shape / new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes = np.concatenate([\n",
    "        box_mins[..., 0:1],\n",
    "        box_mins[..., 1:2],\n",
    "        box_maxes[..., 0:1],\n",
    "        box_maxes[..., 1:2]\n",
    "    ], axis = -1)\n",
    "    boxes *= np.concatenate([image_shape, image_shape], axis = -1)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def boxes_and_scores(feats, anchors, classes_num, input_shape, image_shape):\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = _get_feats(feats, anchors, classes_num, input_shape)\n",
    "    boxes = correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
    "    boxes = np.reshape(boxes, [-1, 4])\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_scores = np.reshape(box_scores, [-1, classes_num])\n",
    "    return boxes, box_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Draw detection frame'''\n",
    "def draw_bbox(image, bboxes, classes):\n",
    "    \"\"\"\n",
    "    bboxes: [x_min, y_min, x_max, y_max, probability, cls_id] format coordinates.\n",
    "    \"\"\"\n",
    "    num_classes = len(classes)\n",
    "    image_h, image_w, _ = image.shape\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        fontScale = 0.5\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 600)\n",
    "        c1, c2 = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "        cv2.rectangle(image, c1, c2, bbox_color, bbox_thick)\n",
    "    return image\n",
    "\n",
    "\n",
    "def nms_boxes(boxes, scores):\n",
    "    \"\"\"Suppress non-maximal boxes.\n",
    "\n",
    "    # Arguments\n",
    "        boxes: ndarray, boxes of objects.\n",
    "        scores: ndarray, scores of objects.\n",
    "\n",
    "    # Returns\n",
    "        keep: ndarray, index of effective boxes.\n",
    "    \"\"\"\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2-x1+1)*(y2-y1+1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w1 = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h1 = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w1 * h1\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        inds = np.where(ovr <= 0.55)[0]  # threshold\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, boxes, scores, classes):\n",
    "    _, ax = plt.subplots(1)\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    image_h, image_w, _ = image.shape\n",
    "\n",
    "    for i, bbox in enumerate(boxes):\n",
    "        [top, left, bottom, right] = bbox\n",
    "        width, height = right - left, bottom - top\n",
    "        center_x, center_y = left + width*0.5, top + height*0.5\n",
    "        score, class_index = scores[i], classes[i]\n",
    "        label = '{}: {:.4f}'.format(class_names[class_index], score) \n",
    "        color = tuple([color/255 for color in colors[class_index]])\n",
    "        ax.add_patch(Rectangle((left, top), width, height,\n",
    "                               edgecolor=color, facecolor='none'))\n",
    "        ax.annotate(label, (center_x, center_y), color=color, weight='bold', \n",
    "                    fontsize=12, ha='center', va='center')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(yolo_outputs, image_shape, class_names, anchors):\n",
    "    score_thresh = 0.2\n",
    "    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "    boxes = []\n",
    "    box_scores = []\n",
    "    input_shape = np.shape(yolo_outputs[0])[1 : 3]\n",
    "    input_shape = np.array(input_shape)*32\n",
    "\n",
    "    for i in range(len(yolo_outputs)):\n",
    "        _boxes, _box_scores = boxes_and_scores(\n",
    "            yolo_outputs[i], anchors[anchor_mask[i]], len(class_names), \n",
    "            input_shape, image_shape)\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "    boxes = np.concatenate(boxes, axis = 0)\n",
    "    box_scores = np.concatenate(box_scores, axis = 0)\n",
    "\n",
    "    mask = box_scores >= score_thresh\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    for c in range(len(class_names)):\n",
    "        class_boxes_np = boxes[mask[:, c]]\n",
    "        class_box_scores_np = box_scores[:, c]\n",
    "        class_box_scores_np = class_box_scores_np[mask[:, c]]\n",
    "        nms_index_np = nms_boxes(class_boxes_np, class_box_scores_np) \n",
    "        class_boxes_np = class_boxes_np[nms_index_np]\n",
    "        class_box_scores_np = class_box_scores_np[nms_index_np]\n",
    "        classes_np = np.ones_like(class_box_scores_np, dtype = np.int32) * c\n",
    "        boxes_.append(class_boxes_np)\n",
    "        scores_.append(class_box_scores_np)\n",
    "        classes_.append(classes_np)\n",
    "    boxes_ = np.concatenate(boxes_, axis = 0)\n",
    "    scores_ = np.concatenate(scores_, axis = 0)\n",
    "    classes_ = np.concatenate(classes_, axis = 0)\n",
    "\n",
    "    return boxes_, scores_, classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that our original images are 640x480 so we need to preprocess them\n",
    "later to make sure it fits our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'img'\n",
    "original_images = [i for i in os.listdir(image_folder) if i.endswith(\"JPEG\")]\n",
    "total_images = len(original_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use VART\n",
    "Now we should be able to use VART to do image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpu = overlay.runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTensors = dpu.get_input_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputTensors = dpu.get_output_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeIn = tuple(inputTensors[0].dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeOut0 = (tuple(outputTensors[0].dims)) # (1, 13, 13, 75)\n",
    "shapeOut1 = (tuple(outputTensors[1].dims)) # (1, 26, 26, 75)\n",
    "shapeOut2 = (tuple(outputTensors[2].dims)) # (1, 52, 52, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputSize0 = int(outputTensors[0].get_data_size() / shapeIn[0]) # 12675\n",
    "outputSize1 = int(outputTensors[1].get_data_size() / shapeIn[0]) # 50700\n",
    "outputSize2 = int(outputTensors[2].get_data_size() / shapeIn[0]) # 202800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a few buffers to store input and output data. They will be reused\n",
    "during multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "output_data = [np.empty(shapeOut0, dtype=np.float32, order=\"C\"), \n",
    "               np.empty(shapeOut1, dtype=np.float32, order=\"C\"),\n",
    "               np.empty(shapeOut2, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we have a list of `original_images`. \n",
    "We can now define a new function `run()` which takes the image index as \n",
    "the input, then decode and post-process the output as the detection result.\n",
    "With the argument `display` set to `True`, the original image as well as the\n",
    "detected objects and their labels can be rendered.\n",
    "\n",
    "It is obvious that the range of `image_index` should be [0, `total_images`-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(image_index, display=False):\n",
    "    # Read input image\n",
    "    input_image = cv2.imread(os.path.join(image_folder, original_images[image_index]))\n",
    "    \n",
    "    # Pre-processing\n",
    "    image_size = input_image.shape[:2]\n",
    "    image_data = np.array(pre_process(input_image, (416, 416)), dtype=np.float32)\n",
    "    \n",
    "    # Fetch data to DPU and trigger it\n",
    "    image[0,...] = image_data.reshape(shapeIn[1:])\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    \n",
    "    # Retrieve output data\n",
    "    conv_out0 = np.reshape(output_data[0], shapeOut0)\n",
    "    conv_out1 = np.reshape(output_data[1], shapeOut1)\n",
    "    conv_out2 = np.reshape(output_data[2], shapeOut2)\n",
    "    yolo_outputs = [conv_out0, conv_out1, conv_out2]\n",
    "    \n",
    "    # Decode output from YOLOv3\n",
    "    boxes, scores, classes = evaluate(yolo_outputs, image_size, class_names, anchors)\n",
    "    \n",
    "    if display:\n",
    "        _ = draw_boxes(input_image, boxes, scores, classes)\n",
    "    print(\"Number of detected objects: {}\".format(len(boxes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it for 1 image and print out the detected label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(1, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run it for multiple images as shown below. In this example\n",
    "we have only used 1 thread; in principle, users should be able to boost\n",
    "the performance by employing more threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "[run(i) for i in range(total_images)]\n",
    "time2 = time.time()\n",
    "fps = total_images/(time2-time1)\n",
    "print(\"Performance: {} FPS\".format(fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to remove references to `vart.Runner` and let Python garbage-collect\n",
    "the unused graph objects. This will make sure we can run other notebooks without\n",
    "any issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del overlay\n",
    "del dpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Copyright (C) 2021 Xilinx, Inc\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0 License\n",
    "\n",
    "----\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
